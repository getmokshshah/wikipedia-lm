model:
  vocab_size: 32000
  d_model: 512
  n_heads: 8
  n_layers: 6
  d_ff: 2048
  max_length: 512
  dropout: 0.1

training:
  batch_size: 16
  learning_rate: 0.0005 
  max_steps: 50000
  eval_steps: 2500
  save_steps: 5000
  warmup_steps: 4000

data:
  max_articles: 50000
  min_length: 100
  max_length: 3000
  val_split: 0.1
  test_split: 0.05